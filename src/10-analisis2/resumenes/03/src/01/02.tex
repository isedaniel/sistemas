\section{Unidad 2}

\subsection{Derivadas parciales}

La \textbf{derivada en un punto} \(P = (a,b)\),
de una función de una variable \(f(x)\),
devuelve la \textit{pendiente} \(m\),
de una recta que es tangente a \(f\) en el punto \(P\).

\vspace{.25cm}
\begin{equation*}
    \frac{df}{dx} = \lim_{\Delta x \to 0}\frac{\Delta y}{\Delta x} =
    \lim_{x \to a}\frac{f(x) - f(a)}{x-a}
\end{equation*}
\vspace{.25cm}

La derivada en funciones de dos variables sigue la misma idea:
aplicamos la derivada a cada una de las variables por separado,
considerando a la otra como constante.
Por eso hablamos de \textbf{derivada parcial}.

\begin{align*}
    \frac{\partial f}{\partial x} = f_x \\
    \\
    \frac{\partial f}{\partial y} = f_y \\
\end{align*}

Geométricamente,
podemos interpretar la derivada parcial respecto de \(x\)
en el punto \(P = (a, b, f(a,b))\),
como la \textit{pendiente} \(m\) de una recta tangente a la curva formada por
la intersección de \(f\) y el plano \(x = a\).
Lo mismo sucedería con la derivada parcial con respecto a \(y\).

\begin{figure}[H]
    \centering
    \caption{Interpretación geométrica de la derivada parcial}
    \includegraphics[scale=.8]{./img/01-02-derivada-parcial-geometrica.png}
\end{figure}

\vspace{.5cm}
\textbf{Ejemplo.}

Encontramos derivadas parciales de \(f(x,y) = x^{3} + x^{2}y^{3} - 2y^{2}\):

\begin{align*}
    f_x = 3x^{2} + 2xy^{3} \\
    f_y = 3x^{2}y^{2} - 4y \\
\end{align*}

\subsection{Propiedades y reglas de la derivada parcial}

\begin{enumerate}
    \item Con \(a\) constante:
          \begin{equation*}
              (a \cdot f)_x = a\cdot f_x
          \end{equation*}
    \item Distributiva respecto de la suma y resta:
          \begin{equation*}
              (f \pm g)_x = f_x \pm g_x
          \end{equation*}
    \item Regla del producto:
          \begin{equation*}
              (f\cdot g)_x = f_x\cdot g + f\cdot g_x
          \end{equation*}
    \item Regla del cociente:
          \begin{equation*}
              \left(\frac{f}{g}\right)_x = \frac{f_x\cdot g - f\cdot g_x}{g^{2}}
          \end{equation*}
    \item Regla de la cadena:
          Derivada parcial de \(g\), con \(f\) como está,
          por derivada parcial de \(f\):
          \begin{equation*}
              (g(f))_x = g(f)_x \cdot f_x
          \end{equation*}
\end{enumerate}

\subsection{Cálculo de derivada parcial por definición}

\subsubsection{Cuando la derivada no es continua en un punto}

Calculamos por definición,
manteniendo una constante.

\vspace{.5cm}
\textbf{Ejemplo.}

Calcular derivadas parciales de \(\sqrt[3]{x^{3} + y^{3}}\) en el origen:

Si calculamos derivada directamente:
\begin{align*}
    f_x & = \frac{1}{3}(x^{3} + y^{3})^{-2/3} \cdot 3x^{2} \\
    f_x & = \frac{x^{2}}{\sqrt[3]{(x^{3} + y^{3})^{2}}} \\
\end{align*}

Si evaluaramos esta derivada parcial en el origen,
encontraríamos una indeterminación.
Sin embargo, 
si derivamos por definición en el punto:

\begin{align*}
    f_x & = \lim_{x \to 0}\frac{f(x,0) - f(0,0)}{x - 0} \\
    f_x & = \lim_{x \to 0} \frac{\sqrt[3]{x^{3}} - 0}{x} \\
    f_x & = \boxed{1} \\
\end{align*}

Vamos con \(f_y\):

\begin{align*}
    f_y & = \lim_{y \to 0}\frac{f(0,y) - f(0,0)}{y - 0} \\
    f_y & = \lim_{y \to 0}\frac{y - 0}{y - 0} \\
    f_y & = \boxed{1}
\end{align*}

Aproximándonos por los ejes \(x\) e \(y\) la derivada tiende a \((1,1)\).


\subsubsection{Cuando está definida por partes}

Donde se da el cambio de función la derivada debe evaluarse por definición.

\vspace{.5cm}
\textbf{Ejemplo.}

Calcular derivada de:
\begin{align*}
    \begin{cases}
        \frac{3xy}{x^{2} + y^{2}} & (x,y)\neq (0,0) \\
        0 & (x,y) = (0,0)
    \end{cases}
\end{align*}

Calculamos por definición donde se produce el cambio de función:

\begin{align*}
     f_x & = \lim_{h \to 0}\frac{f(0 + h,0) - f(0,0)}{h} \\
     f_x & = \lim_{h \to 0}\frac{0 - 0}{h - 0} = \boxed{0} \\
\end{align*}

\begin{align*}
     f_y & = \lim_{h \to 0}\frac{f(0,0 + h) - f(0,0)}{h - 0} \\
     f_y & = \lim_{h \to 0}\frac{0 - 0}{h - 0} = \boxed{0} \\
\end{align*}

La derivada parcial respecto de \(x\) y respecto de \(y\) en \((0,0)\) valen 
ambas 0.

\subsubsection{Cuando puede que una exista y la otra no}

\subsubsection{Derivabilidad y continuidad}

En funciones de una variable la derivabilidad implica continuidad:
si una función es derivable en el punto \(P\),
se puede afirmar que es continua en \(P\).

Lo recíproco, siempre en funciones de una variable,
no se puede asegurar:
que una función sea continua no implica que sea derivable.
El ejemplo clásico es la función \(f(x) = |x|\). 
Esta función no es derivable en \(x = 0\),
puesto que la derivada por izquierda es distinta de la derivada por derecha.

Sin embargo,
en funciones de varias variables,
la derivabilidad \textit{no implica} continuidad.
Por ejemplo, la función \(\frac{3xy}{x^{2} + y^{2}}\).
Sus derivadas parciales en \(x\) y \(y\),
determinadas por definición,
son iguales a 0.
Pero esta función claramente \textit{no es continua} en 0.

Derivabilidad, 
en funciones de varias variables,
no implica continuidad.

\subsection{Derivadas de orden superior o derivadas sucesivas}

Una función de 2 variables independientes tiene \(2^{2}\) 
derivadas de 2\(^{\circ}\) orden:

\begin{align*}
    f_{xx} \quad f_{xy} \quad f_{yy} \quad f_{yx}
\end{align*}

Generalizando,
una función de \(m\) variables tiene \(m^{n}\) derivadas de \(n\) orden.

La notación de las derivadas de segundo orden es:

\begin{equation*}
    f_{xy} = \frac{\partial^{2} f}{\partial y \partial x} \quad 
    f_{xx} = \frac{\partial^{2} f}{\partial x^{2}}
\end{equation*}

\subsection{Teorema de Schwarz}

Si existen en torno al punto \(P\) \(f_x\),
\(f_y\)
y \(f_{xy}\),
con \(f_{xy}\) continua en \(P\),
\textbf{existe} \(f_{yx}\) y \(f_{yx}|_P = f_{xy}|_P\).

En concreto,
las derivadas cruzadas son iguales 
en todos los puntos del dominio donde sean continuas.

\vspace{.5cm}
\textbf{Ejemplo.}

Hallar derivadas de segundo orden de \(f(x,y) = x \cos y + ye^{x}\):

Hallamos primero derivadas de primer orden:

\begin{align*}
    f_x = \cos y + ye^{x} \quad f_y = -x\sen y + e^{x}
\end{align*}

Buscamos las derivadas de segundo orden:

\begin{align*}
    f_{xy} = -\sen y + e^{x} \quad f_{yx} = -\sen y + e^{x}
\end{align*}

Vemos que ambas son continuas,
por lo cual se cumple el Teorema de Schwarz:
las derivadas cruzadas son iguales.

\subsection{Dos matrices especiales}

\subsubsection{Matriz jacobiana}

Es una matriz \(m \times n\),
cuyas filas son las derivadas parciales de \(m\) funciones,
de \(n\) variables.

Por ejemplo, una matriz jacobiana de dos funciones \(f\) y \(g\),
de dos variables, sería:

\begin{equation*}
\BIG{J =
    \begin{pmatrix}
        \frac{\partial f}{\partial x} & \frac{\partial f}{\partial y} \\
        \frac{\partial g}{\partial x} & \frac{\partial g}{\partial y} \\
    \end{pmatrix}}
\end{equation*}

\subsubsection{Matriz Hessiana}

Matriz de las derivadas parciales \textit{de 2do orden}
de \textit{una} función.
Por ejemplo, la hessiana de una función de 2 variables sería:

\begin{equation*}
\BIG{H =
    \begin{pmatrix}
        f_{xx} & f_{xy} \\
        f_{yx} & f_{yy} \\
    \end{pmatrix}}
\end{equation*}

\subsection{Regla de la cadena}

Si \(f(x,y) = z\),
y podemos expresar x e y en función de t,
es decir, \(x(t)\) e \(y(t)\),
se puede hacer una composición \(z(t)\).

Se puede componer y derivar \(\frac{dz}{dt}\) o, por regla de la cadena:

\begin{equation*}
    \frac{dz}{dt} = \frac{\partial z}{\partial x}\cdot\frac{dx}{dt} + \frac{\partial z}{\partial y}\cdot\frac{dy}{dt}
\end{equation*}

Ahora, 
supongamos \(z = f(x,y)\),
que a su vez \(x = x(u,v)\) e \(y = y(u,v)\).
En este caso,
\(z\) tendrá una derivada parcial respecto de \(u\)
y una derivada parcial respecto de \(v\),
siguiendo la estructura del punto anterior:

\begin{align*}
    z_u = f_x\cdot x_u + f_y \cdot y_u \\
    z_v = f_x\cdot x_v + f_y \cdot y_v \\
\end{align*}

\subsection{Derivada direccional}

Ya hemos visto las derivadas parciales,
que son las tasas de cambio de \(z\) en dirección de los ejes \(x\) e \(y\).

La derivada direccional es la tasa de cambio del campo vectorial en dirección 
de un vector \(\vec{u}\).

El vector \(\vec{u}\) puede definirse básicamente de dos maneras:
\begin{itemize}
    \item Con \textbf{puntos} \(a\) y \(b\), 
    que para referir el vector al origen los restamos \(\vec{u} = b-a\)
    \item Con el \textbf{ángulo} \(\theta\),
    de forma \(\vec{u} = (\cos \theta, \sen \theta)\).
\end{itemize}

Para realizar una derivada direccional el vector debe estar normalizado.
Un vector dado por su ángulo \textit{ya se encuentra normalizado}.
Para normalizar un vector dado por sus puntos operamos:

\begin{equation*}
    \vec{n} = \frac{\vec{u}}{|\vec{u}|}
\end{equation*}

Siendo la magnitud del vector \(|\vec{u}| = \sqrt{a^{2} + b^{2}}\).

Dado el punto \(P = (x_0, y_0, z_0)\), 
la derivada direccional en dirección de \(\vec{u} = (a,b)\) es:

\begin{equation*}
    D_{\vec{u}}f(x,y) = \lim_{h \to 0}
    \frac{f(x_0 + ha, y_0 + hb) - f(x_0,y_0)}{h}
\end{equation*}

\textbf{Teorema de la derivada direccional.}

Si \(f\) es diferenciable en \(P = (x_0,y_0)\),
entonces tiene derivada direccional en sentido de cualquier vector 
\(\vec{u} = (a,b)\), donde:

\begin{equation*}
    D_{\vec{u}}f(x,y) = f_x|_{P} \cdot a + f_y|_{P} \cdot b
\end{equation*}

\textbf{Ejemplo.}

Hallar derivada direccional de \(f(x,y) = x^{3} - 3xy + 4y^{2}\),
en dirección de \(\vec{u}\) con \(\theta = \pi/6\).
Determinar valor de la razón de cambio siguiendo ese vector en \(P = (1,2)\).

Instrucciones:
\begin{itemize}
    \item Primero especificamos/normalizamos el vector
    \item Calculamos derivadas parciales 
    \item Planteo el teorema de la derivada direccional 
    \item Obtengo una expresión
    \item Evaluamos en \(P\)
    \item Llegamos al valor
\end{itemize}

Entonces,
primero especificamos el vector:

\begin{align*}
    \vec{u} = \langle\cos\pi/6,\sen\pi/6 \rangle
\end{align*}

El vector está expresado por su ángulo,
es por lo tanto un \textit{vector unitario} y no es necesario normalizar.

En segundo lugar,
determinamos derivadas parciales:

\begin{align*}
    f_x = 3x^{2} - 3y \quad f_y = 8y - 3x
\end{align*}

Ahora planteamos el teorema de la derivada direccional,
que afirma que:

\begin{equation*}
    D_{\vec{u}}f = f_x|_P\cdot a + f_y|_P\cdot b
\end{equation*}

Por lo tanto:

\begin{align*}
    D_{\vec{u}}f & = (3x^{2} - 3y)|_P\cdot \cos\pi/6 
    + (8y - 3x)|_P\cdot \sen\pi/6 \\
    D_{\vec{u}}f & = (3 - 6) \cdot \frac{\sqrt{3}}{2} 
    + (16 - 3) \cdot \frac{1}{2} \\
    D_{\vec{u}}f & = \boxed{\frac{13 - 3\sqrt{3}}{2}}
\end{align*}

Concluimos que la derivada de \(f\) en dirección de \(\vec{u}\) es 
\(\frac{13 - 3\sqrt{3}}{2}\).

\subsection{Vector gradiente}

Se llama vector gradiente al resultado de la función vectorial:

\begin{equation*}
    \nabla f = \langle f_x, f_y \rangle
\end{equation*}

Es perpendicular a la curva de nivel en el punto \(P\) 
y geométricamente representa la dirección de mayor tasa de cambio de la función,
es decir,
da el valor máximo de la derivada direccional para el punto \(P\) 
y es perpendicular la superficie.

\vspace{.5cm}
\textbf{Ejemplo.}

Dada \(f(x,y)=xe^{y}\), 
determinar en qué dirección la función tiene máxima razón de cambio
y cuál es la tasa de cambio para el punto \(P = (2,0)\).

Primero,
para determinar el gradiente necesitamos las derivadas parciales:

\begin{align*}
    f_x = e^{y} \quad f_y = xe^{y}
\end{align*}

Determinamos gradiente:

\begin{align*}
    \nabla f = \langle e^{y}, xe^{y} \rangle
\end{align*}

Evaluamos gradiente en \(P = (2,0)\):

\begin{align*}
    \nabla f|_{(2,0)} = \langle e^{0}, 2\cdot e^{0} \rangle = \langle1,2\rangle
\end{align*}

Por último,
para determinar la tasa de cambio calculamos el módulo del gradiente en \((2,0)\):

\begin{align*}
    ||\langle1,2\rangle|| = \sqrt{1^{2} + 2^{2}} = \boxed{\sqrt{5}}
\end{align*}

\subsection{Plano tangente}

El vector gradiente es ortogonal a la superficie en un punto.
Por lo tanto,
es también ortogonal a \textit{todas las rectas tangentes a la superficie en 
ese punto}. 
El plano que contiene a todas esas tangentes se denomina \textit{plano tangente}
y el vector gradiente es el \textit{vector normal} de dicho plano.

La expresión que describe ese plano,
en el punto \(P = (x_0, y_0)\), es:

\begin{equation*}
    f_x|_P(x - x_0) + f_y|_P(y - y_0) - z + f|_P = 0
\end{equation*}

Y, de manera general, con la función definida de forma implícita:

\begin{equation*}
    \nabla f(x,y,z)\cdot(x-x_0,y-y_0,z-z_0) = 0
\end{equation*}

Es decir,
dada la superficie \(S\) definida por \(f(x,y,z) = 0\),
diferenciable en el punto \(P = (x_0,y_0,z_0)\),
con \(\nabla f (x,y,z \neq 0)\),
definimos:
\begin{itemize}
    \item Plano tangente a \(S\) en \(P\),
    como el plano que pasa por \(P\) y es normal al gradiente en ese punto.
    \item Recta normal a \(S\) en \(P\),
    como la recta que tiene la dirección del gradiente y pasa por \(P\).
\end{itemize}

Se llama \textit{linealización} de \(f\) en \(P\) a la función
-cuya gráfica es un plano- que sigue:

\begin{equation*}
    \mathcal{L}(x,y)= f|_P + f_x|_P(x - x_0) + f_y|_P(y - y_0)
\end{equation*}

\vspace{.5cm}
\textbf{Ejemplo.}

Encontrar ecuación del plano tangente al paraboloide elíptico 
\(z = 2x^{2} + y^{2}\),
para \(P = (1,1)\).

Primero, determinamos \(z|_P = 3\).

Las derivadas parciales de \(z\) son:

\begin{equation*}
    f_x = 4x \quad \land \quad f_y = 2y
\end{equation*}

Por último, evaluamos y expresamos como plano:

\begin{align*}
    f_x|_P(x - x_0) + f_y|P(y - y_0) - z + f|P & = 0 \\
    4x - 4 + 2y - 2 - z + 3 & = 0 \\
    \boxed{4x + 2y - z - 3 = 0} &
\end{align*}

